{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubhankarm/graphneuralnets/.conda/lib/python3.10/site-packages/torch_geometric/data/dataset.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
      "/home/shubhankarm/graphneuralnets/.conda/lib/python3.10/site-packages/torch_geometric/data/dataset.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
      "/home/shubhankarm/graphneuralnets/.conda/lib/python3.10/site-packages/torch_geometric/io/fs.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ESOL(1128)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rdkit # type: ignore\n",
    "from torch_geometric.datasets import MoleculeNet # type: ignore\n",
    "\n",
    "# Load the ESOL dataset\n",
    "data = MoleculeNet(root=\".\", name=\"ESOL\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7f26214e4190>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "molecule = Chem.MolFromSmiles(data[0]['smiles'])\n",
    "molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type:  <class 'torch_geometric.datasets.molecule_net.MoleculeNet'>\n",
      "Dataset features:  9\n",
      "Dataset target:  734\n",
      "Dataset length:  <bound method InMemoryDataset.len of ESOL(1128)>\n",
      "Dataset sample:  Data(x=[32, 9], edge_index=[2, 68], edge_attr=[68, 3], smiles='OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)C(O)C3O ', y=[1, 1])\n",
      "Sample  nodes:  32\n",
      "Sample  edges:  68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubhankarm/graphneuralnets/.conda/lib/python3.10/site-packages/torch_geometric/data/dataset.py:169: UserWarning: Found floating-point labels while calling `dataset.num_classes`. Returning the number of unique elements. Please make sure that this is expected before proceeding.\n",
      "  warnings.warn(\"Found floating-point labels while calling \"\n"
     ]
    }
   ],
   "source": [
    "# Investigating the dataset\n",
    "print(\"Dataset type: \", type(data))\n",
    "print(\"Dataset features: \", data.num_features)\n",
    "print(\"Dataset target: \", data.num_classes)\n",
    "print(\"Dataset length: \", data.len)\n",
    "print(\"Dataset sample: \", data[0])\n",
    "print(\"Sample  nodes: \", data[0].num_nodes)\n",
    "print(\"Sample  edges: \", data[0].num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 0, 2, 5, 1, 0, 4, 0, 0],\n",
       "        [6, 0, 4, 5, 2, 0, 4, 0, 0],\n",
       "        [6, 0, 4, 5, 1, 0, 4, 0, 1],\n",
       "        [8, 0, 2, 5, 0, 0, 4, 0, 1],\n",
       "        [6, 0, 4, 5, 1, 0, 4, 0, 1],\n",
       "        [8, 0, 2, 5, 0, 0, 4, 0, 0],\n",
       "        [6, 0, 4, 5, 2, 0, 4, 0, 0],\n",
       "        [6, 0, 4, 5, 1, 0, 4, 0, 1],\n",
       "        [8, 0, 2, 5, 0, 0, 4, 0, 1],\n",
       "        [6, 0, 4, 5, 1, 0, 4, 0, 1],\n",
       "        [8, 0, 2, 5, 0, 0, 4, 0, 0],\n",
       "        [6, 0, 4, 5, 1, 0, 4, 0, 0],\n",
       "        [6, 0, 2, 5, 0, 0, 2, 0, 0],\n",
       "        [7, 0, 1, 5, 0, 0, 2, 0, 0],\n",
       "        [6, 0, 3, 5, 0, 0, 3, 1, 1],\n",
       "        [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       "        [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       "        [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       "        [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       "        [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       "        [6, 0, 4, 5, 1, 0, 4, 0, 1],\n",
       "        [8, 0, 2, 5, 1, 0, 4, 0, 0],\n",
       "        [6, 0, 4, 5, 1, 0, 4, 0, 1],\n",
       "        [8, 0, 2, 5, 1, 0, 4, 0, 0],\n",
       "        [6, 0, 4, 5, 1, 0, 4, 0, 1],\n",
       "        [8, 0, 2, 5, 1, 0, 4, 0, 0],\n",
       "        [6, 0, 4, 5, 1, 0, 4, 0, 1],\n",
       "        [8, 0, 2, 5, 1, 0, 4, 0, 0],\n",
       "        [6, 0, 4, 5, 1, 0, 4, 0, 1],\n",
       "        [8, 0, 2, 5, 1, 0, 4, 0, 0],\n",
       "        [6, 0, 4, 5, 1, 0, 4, 0, 1],\n",
       "        [8, 0, 2, 5, 1, 0, 4, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigating the features\n",
    "# Shape: [num_nodes, num_node_features]\n",
    "\n",
    "data[0].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1],\n",
       "        [ 1,  0],\n",
       "        [ 1,  2],\n",
       "        [ 2,  1],\n",
       "        [ 2,  3],\n",
       "        [ 2, 30],\n",
       "        [ 3,  2],\n",
       "        [ 3,  4],\n",
       "        [ 4,  3],\n",
       "        [ 4,  5],\n",
       "        [ 4, 26],\n",
       "        [ 5,  4],\n",
       "        [ 5,  6],\n",
       "        [ 6,  5],\n",
       "        [ 6,  7],\n",
       "        [ 7,  6],\n",
       "        [ 7,  8],\n",
       "        [ 7, 24],\n",
       "        [ 8,  7],\n",
       "        [ 8,  9],\n",
       "        [ 9,  8],\n",
       "        [ 9, 10],\n",
       "        [ 9, 20],\n",
       "        [10,  9],\n",
       "        [10, 11],\n",
       "        [11, 10],\n",
       "        [11, 12],\n",
       "        [11, 14],\n",
       "        [12, 11],\n",
       "        [12, 13],\n",
       "        [13, 12],\n",
       "        [14, 11],\n",
       "        [14, 15],\n",
       "        [14, 19],\n",
       "        [15, 14],\n",
       "        [15, 16],\n",
       "        [16, 15],\n",
       "        [16, 17],\n",
       "        [17, 16],\n",
       "        [17, 18],\n",
       "        [18, 17],\n",
       "        [18, 19],\n",
       "        [19, 14],\n",
       "        [19, 18],\n",
       "        [20,  9],\n",
       "        [20, 21],\n",
       "        [20, 22],\n",
       "        [21, 20],\n",
       "        [22, 20],\n",
       "        [22, 23],\n",
       "        [22, 24],\n",
       "        [23, 22],\n",
       "        [24,  7],\n",
       "        [24, 22],\n",
       "        [24, 25],\n",
       "        [25, 24],\n",
       "        [26,  4],\n",
       "        [26, 27],\n",
       "        [26, 28],\n",
       "        [27, 26],\n",
       "        [28, 26],\n",
       "        [28, 29],\n",
       "        [28, 30],\n",
       "        [29, 28],\n",
       "        [30,  2],\n",
       "        [30, 28],\n",
       "        [30, 31],\n",
       "        [31, 30]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigating the edges in sparse COO format\n",
    "# Shape [2, num_edges]\n",
    "data[0].edge_index.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7700]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, TopKPooling  # type: ignore\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp # type: ignore\n",
    "embedding_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN,self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        \n",
    "        #gcn layers\n",
    "        \n",
    "        self.initial_conv = GCNConv(data.num_features, embedding_size)\n",
    "        \n",
    "        self.conv1 = GCNConv(embedding_size,embedding_size)\n",
    "        self.conv2 = GCNConv(embedding_size,embedding_size)\n",
    "        self.conv3 = GCNConv(embedding_size,embedding_size)\n",
    "        self.conv4 = GCNConv(embedding_size, embedding_size)\n",
    "        \n",
    "        #output layer\n",
    "        \n",
    "        self.out = Linear(2*embedding_size,1)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch_index):\n",
    "        #first conv layer\n",
    "        \n",
    "        hidden_0 = self.initial_conv(x,edge_index)\n",
    "        hidden_0= F.tanh(hidden_0)\n",
    "        \n",
    "        # other 3 conv layers\n",
    "        \n",
    "        hidden_1 = self.conv1(hidden_0, edge_index)\n",
    "        hidden_1 = F.tanh(hidden_1)\n",
    "        \n",
    "        hidden_2 = self.conv2(hidden_1, edge_index)\n",
    "        hidden_2 = F.tanh(hidden_2)\n",
    "        \n",
    "        hidden_3 = self.conv3(hidden_2, edge_index)\n",
    "        hidden_3 = F.tanh(hidden_3)\n",
    "        \n",
    "        hidden_4 = self.conv4(hidden_3, edge_index)\n",
    "        hidden_4 = F.tanh(hidden_4)\n",
    "        \n",
    "        # Global Pooling (stack different aggregations)\n",
    "        \n",
    "        hidden_pool = torch.cat([gap(hidden_4, batch_index),gmp(hidden_4,batch_index)], dim=1)\n",
    "        \n",
    "        # Apply a final (linear) classifier.\n",
    "        \n",
    "        out = self.out(hidden_pool)\n",
    "        \n",
    "        return out, hidden_pool\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (initial_conv): GCNConv(9, 64)\n",
      "  (conv1): GCNConv(64, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (conv3): GCNConv(64, 64)\n",
      "  (conv4): GCNConv(64, 64)\n",
      "  (out): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "number of parameters:  17409\n"
     ]
    }
   ],
   "source": [
    "model = GCN()\n",
    "print(model)\n",
    "print(\"number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader # type: ignore\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Defining loss function and optimizer\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") # if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Wrap data in a data loader\n",
    "\n",
    "data_size = len(data)\n",
    "numof_graphs_per_batch  = 64\n",
    "loader = DataLoader(data[ :int(data_size*0.8)], batch_size = numof_graphs_per_batch, shuffle=True)\n",
    "test_loader = DataLoader(data[int(data_size*0.2): ],batch_size=numof_graphs_per_batch,shuffle=True)\n",
    "\n",
    "def train(data):\n",
    "    for batch in loader:\n",
    "        batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred,embedding = model(batch.x.float(), batch.edge_index ,batch.batch)\n",
    "        loss = loss_fn(pred,batch.y)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    return loss, embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training....\n",
      "Epoch 0 | Train Loss 9.702274322509766\n",
      "Epoch 100 | Train Loss 2.2547130584716797\n",
      "Epoch 200 | Train Loss 2.0474002361297607\n",
      "Epoch 300 | Train Loss 2.3335750102996826\n",
      "Epoch 400 | Train Loss 1.8020204305648804\n",
      "Epoch 500 | Train Loss 2.5342001914978027\n",
      "Epoch 600 | Train Loss 0.3061600923538208\n",
      "Epoch 700 | Train Loss 0.8480193614959717\n",
      "Epoch 800 | Train Loss 1.2189059257507324\n",
      "Epoch 900 | Train Loss 1.105386734008789\n",
      "Epoch 1000 | Train Loss 4.097634792327881\n",
      "Epoch 1100 | Train Loss 0.43639644980430603\n",
      "Epoch 1200 | Train Loss 0.6314657330513\n",
      "Epoch 1300 | Train Loss 0.6334051489830017\n",
      "Epoch 1400 | Train Loss 0.3910408914089203\n",
      "Epoch 1500 | Train Loss 0.3332185447216034\n",
      "Epoch 1600 | Train Loss 0.5449062585830688\n",
      "Epoch 1700 | Train Loss 0.3734932839870453\n",
      "Epoch 1800 | Train Loss 1.23171067237854\n",
      "Epoch 1900 | Train Loss 0.4067370295524597\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting the training....\")\n",
    "losses= []\n",
    "for epoch in range(2000):\n",
    "    loss,h = train(data)\n",
    "    losses.append(loss)\n",
    "    if epoch%100==0:\n",
    "        print(f\"Epoch {epoch} | Train Loss {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.4948, RMSE: 0.7034\n"
     ]
    }
   ],
   "source": [
    "# testing model performance\n",
    "\n",
    "test_batch = next(iter(test_loader))\n",
    "loss = 0\n",
    "with torch.no_grad():\n",
    "    test_batch.to(device)\n",
    "    pred, embed = model(test_batch.x.float(), test_batch.edge_index, test_batch.batch) \n",
    "    loss += loss_fn(pred, test_batch.y)\n",
    "\n",
    "mse = loss.item()\n",
    "rmse = mse ** 0.5\n",
    "\n",
    "print(f'MSE: {mse:.4f}, RMSE: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE: 0.5271, Average RMSE: 0.7175\n"
     ]
    }
   ],
   "source": [
    "mse_values = []\n",
    "rmse_values = []\n",
    "for _ in range(5):\n",
    "    test_batch = next(iter(test_loader))\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        test_batch.to(device)\n",
    "        pred, embed = model(test_batch.x.float(), test_batch.edge_index, test_batch.batch) \n",
    "        loss += loss_fn(pred, test_batch.y)\n",
    "    mse = loss.item()\n",
    "    rmse = mse ** 0.5\n",
    "    mse_values.append(mse)\n",
    "    rmse_values.append(rmse)\n",
    "\n",
    "avg_mse = sum(mse_values) / 5\n",
    "avg_rmse = sum(rmse_values) / 5\n",
    "\n",
    "print(f'Average MSE: {avg_mse:.4f}, Average RMSE: {avg_rmse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the Training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize learning (training loss)\n",
    "import seaborn as sns\n",
    "losses_float = [float(loss.cpu().detach().numpy()) for loss in losses] \n",
    "loss_indices = [i for i,l in enumerate(losses_float)] \n",
    "plt = sns.lineplot(loss_indices, losses_float)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Visualize learning (training loss)\n",
    "plt.plot(range(len(losses)), losses, marker='o')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Analyze the results for one batch\n",
    "test_batch = next(iter(test_loader))\n",
    "with torch.no_grad():\n",
    "    test_batch.to(device)\n",
    "    pred, embed = model(test_batch.x.float(), test_batch.edge_index, test_batch.batch) \n",
    "    df = pd.DataFrame()\n",
    "    df[\"y_real\"] = test_batch.y.tolist()\n",
    "    df[\"y_pred\"] = pred.tolist()\n",
    "df[\"y_real\"] = df[\"y_real\"].apply(lambda row: row[0])\n",
    "df[\"y_pred\"] = df[\"y_pred\"].apply(lambda row: row[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = sns.scatterplot(data=df, x=\"y_real\", y=\"y_pred\")\n",
    "plt.set(xlim=(-7, 2))\n",
    "plt.set(ylim=(-7, 2))\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
